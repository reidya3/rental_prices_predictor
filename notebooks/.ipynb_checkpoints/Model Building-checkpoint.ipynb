{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building \n",
    "\n",
    "The ml technique I need is regression. In this example, I used multiple linear regression, lasso regression, random forest, and a gradient boosted tree. I tuned the two tree-based models using gridsearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#get dummy data\n",
    "# chose revalant columns\n",
    "# train test split\n",
    "# multiple linear regressiom\n",
    "# lasso regression\n",
    "#  random forest\n",
    "# gradient boosted tree\n",
    "# suport ve~tor regression\n",
    "# tune these models using gridsearcCV\n",
    "# test enseembles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_df = pd.read_hdf(\"../data/after_eda.h5\")\n",
    "price_level = pd.to_numeric(rent_df['price level'],errors='coerce')\n",
    "rent_df['price level'].fillna(value = price_level.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2036 entries, 0 to 2036\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Monthly rent price(€)  2036 non-null   float64\n",
      " 1   Type                   2036 non-null   object \n",
      " 2   Address                2036 non-null   object \n",
      " 3   Post code              2036 non-null   object \n",
      " 4   Bedroom(s)             2036 non-null   int32  \n",
      " 5   Bathroom(s)            2036 non-null   int32  \n",
      " 6   Property desc          2036 non-null   object \n",
      " 7   Week YN                2036 non-null   int64  \n",
      " 8   Month YN               2036 non-null   int64  \n",
      " 9   Furnished Status       2036 non-null   int32  \n",
      " 10  Longitude              2036 non-null   float64\n",
      " 11  latitude               2036 non-null   float64\n",
      " 12  dist_bridge            2036 non-null   float64\n",
      " 13  dist_ifsc              2036 non-null   float64\n",
      " 14  dist_silicon_docks     2036 non-null   float64\n",
      " 15  coord                  2036 non-null   object \n",
      " 16  price level            2036 non-null   float64\n",
      " 17  rating                 2036 non-null   float64\n",
      "dtypes: float64(8), int32(3), int64(2), object(5)\n",
      "memory usage: 278.4+ KB\n"
     ]
    }
   ],
   "source": [
    "rent_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = rent_df[[\"Monthly rent price(€)\",'Type','Post code','Bedroom(s)','Bathroom(s)','Week YN','Month YN','Furnished Status','dist_bridge','dist_ifsc','dist_silicon_docks','price level','rating' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with categorical variables\n",
    "\n",
    "The pandas get_dummies method is used to convert categorical variable into dummy/indicator variables using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get dummies\n",
    "df_dum = pd.get_dummies(model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Monthly rent price(€)', 'Bedroom(s)', 'Bathroom(s)', 'Week YN',\n",
       "       'Month YN', 'Furnished Status', 'dist_bridge', 'dist_ifsc',\n",
       "       'dist_silicon_docks', 'price level', 'rating', 'Type_apartment',\n",
       "       'Type_house', 'Post code_1', 'Post code_10', 'Post code_11',\n",
       "       'Post code_12', 'Post code_13', 'Post code_14', 'Post code_15',\n",
       "       'Post code_16', 'Post code_17', 'Post code_18', 'Post code_2',\n",
       "       'Post code_20', 'Post code_22', 'Post code_24', 'Post code_3',\n",
       "       'Post code_4', 'Post code_5', 'Post code_6', 'Post code_6w',\n",
       "       'Post code_7', 'Post code_8', 'Post code_9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dum.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a train test split as want our models to generalize well (i.e. to prevent overfitting).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "x = df_dum.drop('Monthly rent price(€)', axis=1)\n",
    "y = df_dum['Monthly rent price(€)'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1628, 34)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used two different libaries to implement the multiple linear regression, namely statsmodels and scikit-learn. Although the scikit-learn is more commonly used, the statsmodel can provide us with additional information such\n",
    "as  the adjusted R-squared, the f statistic, whether a feature is significant or not and other information detailed down below.\n",
    "\n",
    "To evaluate a particular model, I used three-fold cross-validation using the metric negative absolute mean error. A negative error is helpful in finding the best algorithm when you are comparing multiple algorithms through GridSearchCV().\n",
    "\n",
    "This is because, after training, GridSearchCV() ranks all the algorithms(estimators) and tells you which one is the best. When you use an error function, an estimator with higher score will be ranked higher by scikit-learn, which is not true in the case of MAE.\n",
    "\n",
    "To deal with this, the library flips the sign of error, so the highest MAE will be ranked lowest and vice versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm = x = sm.add_constant(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y,X_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.663</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.658</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   127.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 04 Jul 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:23:23</td>     <th>  Log-Likelihood:    </th> <td> -15500.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2036</td>      <th>  AIC:               </th> <td>3.106e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2004</td>      <th>  BIC:               </th> <td>3.124e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    31</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>  250.1637</td> <td>  255.675</td> <td>    0.978</td> <td> 0.328</td> <td> -251.253</td> <td>  751.580</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Bedroom(s)</th>         <td>  435.9790</td> <td>   17.573</td> <td>   24.809</td> <td> 0.000</td> <td>  401.515</td> <td>  470.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Bathroom(s)</th>        <td>  272.1125</td> <td>   20.694</td> <td>   13.149</td> <td> 0.000</td> <td>  231.528</td> <td>  312.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Week YN</th>            <td>  168.5121</td> <td>  131.387</td> <td>    1.283</td> <td> 0.200</td> <td>  -89.157</td> <td>  426.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month YN</th>           <td>   81.6516</td> <td>  128.424</td> <td>    0.636</td> <td> 0.525</td> <td> -170.207</td> <td>  333.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Furnished Status</th>   <td> -256.7424</td> <td>   60.590</td> <td>   -4.237</td> <td> 0.000</td> <td> -375.569</td> <td> -137.916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dist_bridge</th>        <td>  -19.3128</td> <td>   39.656</td> <td>   -0.487</td> <td> 0.626</td> <td>  -97.084</td> <td>   58.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dist_ifsc</th>          <td>  186.3357</td> <td>   92.453</td> <td>    2.015</td> <td> 0.044</td> <td>    5.022</td> <td>  367.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dist_silicon_docks</th> <td> -194.4502</td> <td>   63.513</td> <td>   -3.062</td> <td> 0.002</td> <td> -319.009</td> <td>  -69.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price level</th>        <td>   72.0874</td> <td>   31.951</td> <td>    2.256</td> <td> 0.024</td> <td>    9.428</td> <td>  134.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating</th>             <td>  100.5659</td> <td>  121.165</td> <td>    0.830</td> <td> 0.407</td> <td> -137.056</td> <td>  338.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_apartment</th>     <td>   71.1404</td> <td>  128.825</td> <td>    0.552</td> <td> 0.581</td> <td> -181.504</td> <td>  323.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_house</th>         <td>  179.0233</td> <td>  128.911</td> <td>    1.389</td> <td> 0.165</td> <td>  -73.790</td> <td>  431.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_1</th>        <td>  315.9655</td> <td>   68.391</td> <td>    4.620</td> <td> 0.000</td> <td>  181.840</td> <td>  450.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_10</th>       <td>  197.7775</td> <td>  275.467</td> <td>    0.718</td> <td> 0.473</td> <td> -342.454</td> <td>  738.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_11</th>       <td> -451.5047</td> <td>  106.574</td> <td>   -4.237</td> <td> 0.000</td> <td> -660.513</td> <td> -242.496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_12</th>       <td> -118.7477</td> <td>   99.032</td> <td>   -1.199</td> <td> 0.231</td> <td> -312.964</td> <td>   75.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_13</th>       <td>  -35.5407</td> <td>  121.540</td> <td>   -0.292</td> <td> 0.770</td> <td> -273.899</td> <td>  202.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_14</th>       <td>  -16.2253</td> <td>   74.207</td> <td>   -0.219</td> <td> 0.827</td> <td> -161.756</td> <td>  129.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_15</th>       <td>  -85.5363</td> <td>   90.063</td> <td>   -0.950</td> <td> 0.342</td> <td> -262.162</td> <td>   91.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_16</th>       <td>  -66.6250</td> <td>  133.163</td> <td>   -0.500</td> <td> 0.617</td> <td> -327.778</td> <td>  194.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_17</th>       <td> -106.7640</td> <td>  278.043</td> <td>   -0.384</td> <td> 0.701</td> <td> -652.048</td> <td>  438.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_18</th>       <td>   73.9450</td> <td>   85.063</td> <td>    0.869</td> <td> 0.385</td> <td>  -92.876</td> <td>  240.766</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_2</th>        <td>  413.6980</td> <td>   62.345</td> <td>    6.636</td> <td> 0.000</td> <td>  291.430</td> <td>  535.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_20</th>       <td>   26.5151</td> <td>  171.885</td> <td>    0.154</td> <td> 0.877</td> <td> -310.577</td> <td>  363.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_22</th>       <td>  -61.7717</td> <td>  126.616</td> <td>   -0.488</td> <td> 0.626</td> <td> -310.084</td> <td>  186.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_24</th>       <td> -139.8691</td> <td>  121.933</td> <td>   -1.147</td> <td> 0.251</td> <td> -378.998</td> <td>   99.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_3</th>        <td>   58.4694</td> <td>   76.973</td> <td>    0.760</td> <td> 0.448</td> <td>  -92.486</td> <td>  209.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_4</th>        <td>  259.3979</td> <td>   68.962</td> <td>    3.761</td> <td> 0.000</td> <td>  124.153</td> <td>  394.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_5</th>        <td> -104.4632</td> <td>  118.316</td> <td>   -0.883</td> <td> 0.377</td> <td> -336.498</td> <td>  127.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_6</th>        <td>  109.0410</td> <td>   64.058</td> <td>    1.702</td> <td> 0.089</td> <td>  -16.586</td> <td>  234.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_6w</th>       <td>  -94.6625</td> <td>  109.466</td> <td>   -0.865</td> <td> 0.387</td> <td> -309.341</td> <td>  120.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_7</th>        <td>   39.7820</td> <td>   66.163</td> <td>    0.601</td> <td> 0.548</td> <td>  -89.974</td> <td>  169.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_8</th>        <td>   74.4786</td> <td>   56.722</td> <td>    1.313</td> <td> 0.189</td> <td>  -36.761</td> <td>  185.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Post code_9</th>        <td>  -37.1961</td> <td>   78.711</td> <td>   -0.473</td> <td> 0.637</td> <td> -191.559</td> <td>  117.167</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1255.213</td> <th>  Durbin-Watson:     </th> <td>   1.814</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>93773.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.094</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>35.982</td>  <th>  Cond. No.          </th> <td>1.38e+16</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 8.83e-28. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.663\n",
       "Model:                            OLS   Adj. R-squared:                  0.658\n",
       "Method:                 Least Squares   F-statistic:                     127.3\n",
       "Date:                Sat, 04 Jul 2020   Prob (F-statistic):               0.00\n",
       "Time:                        16:23:23   Log-Likelihood:                -15500.\n",
       "No. Observations:                2036   AIC:                         3.106e+04\n",
       "Df Residuals:                    2004   BIC:                         3.124e+04\n",
       "Df Model:                          31                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                250.1637    255.675      0.978      0.328    -251.253     751.580\n",
       "Bedroom(s)           435.9790     17.573     24.809      0.000     401.515     470.443\n",
       "Bathroom(s)          272.1125     20.694     13.149      0.000     231.528     312.697\n",
       "Week YN              168.5121    131.387      1.283      0.200     -89.157     426.181\n",
       "Month YN              81.6516    128.424      0.636      0.525    -170.207     333.510\n",
       "Furnished Status    -256.7424     60.590     -4.237      0.000    -375.569    -137.916\n",
       "dist_bridge          -19.3128     39.656     -0.487      0.626     -97.084      58.458\n",
       "dist_ifsc            186.3357     92.453      2.015      0.044       5.022     367.649\n",
       "dist_silicon_docks  -194.4502     63.513     -3.062      0.002    -319.009     -69.891\n",
       "price level           72.0874     31.951      2.256      0.024       9.428     134.747\n",
       "rating               100.5659    121.165      0.830      0.407    -137.056     338.188\n",
       "Type_apartment        71.1404    128.825      0.552      0.581    -181.504     323.785\n",
       "Type_house           179.0233    128.911      1.389      0.165     -73.790     431.837\n",
       "Post code_1          315.9655     68.391      4.620      0.000     181.840     450.091\n",
       "Post code_10         197.7775    275.467      0.718      0.473    -342.454     738.009\n",
       "Post code_11        -451.5047    106.574     -4.237      0.000    -660.513    -242.496\n",
       "Post code_12        -118.7477     99.032     -1.199      0.231    -312.964      75.469\n",
       "Post code_13         -35.5407    121.540     -0.292      0.770    -273.899     202.818\n",
       "Post code_14         -16.2253     74.207     -0.219      0.827    -161.756     129.305\n",
       "Post code_15         -85.5363     90.063     -0.950      0.342    -262.162      91.090\n",
       "Post code_16         -66.6250    133.163     -0.500      0.617    -327.778     194.528\n",
       "Post code_17        -106.7640    278.043     -0.384      0.701    -652.048     438.520\n",
       "Post code_18          73.9450     85.063      0.869      0.385     -92.876     240.766\n",
       "Post code_2          413.6980     62.345      6.636      0.000     291.430     535.966\n",
       "Post code_20          26.5151    171.885      0.154      0.877    -310.577     363.607\n",
       "Post code_22         -61.7717    126.616     -0.488      0.626    -310.084     186.540\n",
       "Post code_24        -139.8691    121.933     -1.147      0.251    -378.998      99.260\n",
       "Post code_3           58.4694     76.973      0.760      0.448     -92.486     209.425\n",
       "Post code_4          259.3979     68.962      3.761      0.000     124.153     394.643\n",
       "Post code_5         -104.4632    118.316     -0.883      0.377    -336.498     127.571\n",
       "Post code_6          109.0410     64.058      1.702      0.089     -16.586     234.668\n",
       "Post code_6w         -94.6625    109.466     -0.865      0.387    -309.341     120.016\n",
       "Post code_7           39.7820     66.163      0.601      0.548     -89.974     169.538\n",
       "Post code_8           74.4786     56.722      1.313      0.189     -36.761     185.719\n",
       "Post code_9          -37.1961     78.711     -0.473      0.637    -191.559     117.167\n",
       "==============================================================================\n",
       "Omnibus:                     1255.213   Durbin-Watson:                   1.814\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            93773.004\n",
       "Skew:                           2.094   Prob(JB):                         0.00\n",
       "Kurtosis:                      35.982   Cond. No.                     1.38e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.83e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-40847362.65985504"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(lm,X_train,y_train, scoring=\"neg_mean_absolute_error\",cv=3 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the multiple linear regression model performed very poorly on the training data.\n",
    "\n",
    "The next port of call was to use lasso regression. We used  lasso regression as our dataset is sparse as a result of the dummy variables. The lasso regularization will actually set less-important predictors to 0 and help you with choosing the predictors that can be left out of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tonyr\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1218011.5753569603, tolerance: 109157.46581741958\n",
      "  positive)\n",
      "C:\\Users\\tonyr\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 875831.4181216657, tolerance: 77177.81610887701\n",
      "  positive)\n",
      "C:\\Users\\tonyr\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 999009.0733196735, tolerance: 75332.04140184502\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-293.52781369306985"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_l = linear_model.Lasso()\n",
    "lm_l.fit(X_train,y_train)\n",
    "np.mean(cross_val_score(lm_l,X_train,y_train, scoring=\"neg_mean_absolute_error\",cv=3 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lasso regression comes with a parameter, alpha, and the higher the alpha, the most feature coefficients are zero.\n",
    "\n",
    "That is, when alpha is 0, Lasso regression produces the same coefficients as a linear regression. When alpha is very very large, all coefficients are zero.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = []\n",
    "error = []\n",
    "for i in range(1,100):\n",
    "    alpha.append(i/10)\n",
    "    lml = Lasso(alpha = i/10)\n",
    "    error.append(np.mean(cross_val_score(lml,X_train,y_train, scoring=\"neg_mean_absolute_error\",cv=3 )))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.5, -291.66789742701025)\n"
     ]
    }
   ],
   "source": [
    "plt.plot(alpha, error)\n",
    "plt.show()\n",
    "print(max(tuple(zip(alpha,error)), key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-291.66789742701025"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_l = linear_model.Lasso(alpha=3.5)\n",
    "lm_l.fit(X_train,y_train)\n",
    "np.mean(cross_val_score(lm_l,X_train,y_train, scoring=\"neg_mean_absolute_error\",cv=3 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-278.68202010987494"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "np.mean(cross_val_score(rf,X_train,y_train,scoring=\"neg_mean_absolute_error\",cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the model....\n",
    "\n",
    "Parameters is a dictionary with parameters names as keys and lists of parameter settings to try as values, or a list of such dictionaries, in which case the grids spanned by each dictionary in the list are explored. N_estimators:\n",
    "The number of trees in the forest. Criterion contains two error functions MSE MAE. Max_features: The number of features to consider when looking for the best split.  If “auto”, then max_features=sqrt(n_features).If “sqrt”, then max_features=sqrt(n_features) (same as “auto”). If “log2”, then max_features=log2(n_features).(n_features is the number of features available.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters = {'n_estimators':range(10,300,10),'criterion':('mse','mae'), 'max_features':('auto','sqrt','log2')}\n",
    "gs = GridSearchCV(rf, parameters,scoring= \"neg_mean_absolute_error\", cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By tuning, we improved our model by a small amount. Looking at our best estimator, it comes as no surprise that our criterion is MAE as we score based onn MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ('mse', 'mae'),\n",
       "                         'max_features': ('auto', 'sqrt', 'log2'),\n",
       "                         'n_estimators': range(10, 300, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-275.49575834369665"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
       "                      max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=150, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosted tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=0, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = GradientBoostingRegressor(random_state=0)\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-277.6940526775665"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(rf,X_train,y_train,scoring=\"neg_mean_absolute_error\",cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_iter_n...\n",
       "                                                 presort='deprecated',\n",
       "                                                 random_state=0, subsample=1.0,\n",
       "                                                 tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ('mse', 'mae'),\n",
       "                         'max_features': ('auto', 'sqrt', 'log2'),\n",
       "                         'n_estimators': range(10, 300, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr = GridSearchCV(reg, parameters,scoring= \"neg_mean_absolute_error\", cv=3)\n",
    "gr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='mae', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features='auto', max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=0, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_iter_n...\n",
       "                                                 presort='deprecated',\n",
       "                                                 random_state=0, subsample=1.0,\n",
       "                                                 tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ('mse', 'mae'),\n",
       "                         'max_features': ('auto', 'sqrt', 'log2'),\n",
       "                         'n_estimators': range(10, 300, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find ratios of combined models\n",
    "gr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tpread_lm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-93427ea1f609>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtpread_lm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtpread_lml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtpred_rf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtpred_reg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tpread_lm' is not defined"
     ]
    }
   ],
   "source": [
    "tpread_lm = lm.predict(X_test)\n",
    "tpread_lml = lm_l.predict(X_test)\n",
    "tpred_rf = gs.best_estimator_.predict(X_test)\n",
    "tpred_reg = gr.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test,tpread_lm))\n",
    "print(mean_absolute_error(y_test,tpread_lml))\n",
    "print(mean_absolute_error(y_test,tpred_rf))\n",
    "print(mean_absolute_error(y_test,tpred_reg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
